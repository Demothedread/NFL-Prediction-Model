{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08e684783d9c25bbb9b67d783931ab56d1e5f3ae"
   },
   "source": [
    "# NFL Betting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "_uuid": "f2f7797d36908d431dabf998e39cccd5c88a80cb"
   },
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    import sklearn\n",
    "\n",
    "# required machine learning packages\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV as CCV\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "import xgboost as xgb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c840ac5e9055018937ebad8bf22d482bc90b9f96"
   },
   "source": [
    "# Loading and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f84e90ae7bf60fb52b299ded80580242c36a01e7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading CSV files downloaded from Kaggle\n",
    "df = pd.read_csv(\"spreadspoke_scores.csv\")\n",
    "teams = pd.read_csv(\"nfl_teams.csv\")\n",
    "games_elo = pd.read_csv(\"nfl_games1.csv\")\n",
    "games_elo18 = pd.read_csv(\"nfl_games_2019_1.csv\")\n",
    "games_elo = games_elo.append(games_elo18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d455153ebd7068ca96d50ce98a8290fba7bd734e"
   },
   "outputs": [],
   "source": [
    "# replacing blank strings with NaN\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d455153ebd7068ca96d50ce98a8290fba7bd734e"
   },
   "outputs": [],
   "source": [
    "# removing rows from specific columns that have null values, resetting index and changing data types\n",
    "df = df[(df.score_home.isnull() == False) & (df.team_favorite_id.isnull() == False) & (df.over_under_line.isnull() == False) &\n",
    "        (df.schedule_season >= 1979)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d455153ebd7068ca96d50ce98a8290fba7bd734e"
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df['over_under_line'] = df.over_under_line.astype(float)\n",
    "\n",
    "# mapping team_id to the correct teams\n",
    "df['team_home'] = df.team_home.map(teams.set_index('team_name')['team_id'].to_dict())\n",
    "df['team_away'] = df.team_away.map(teams.set_index('team_name')['team_id'].to_dict())\n",
    "\n",
    "# fix team_favorite_id for Colts in 1969 and 1971 SB\n",
    "df.loc[(df.schedule_season == 1968) & (df.schedule_week == 'Superbowl'), 'team_favorite_id'] = 'IND'\n",
    "df.loc[(df.schedule_season == 1970) & (df.schedule_week == 'Superbowl'), 'team_favorite_id'] = 'IND'\n",
    "\n",
    "# creating home favorite and away favorite columns (fill na with 0's)\n",
    "df.loc[df.team_favorite_id == df.team_home, 'home_favorite'] = 1\n",
    "df.loc[df.team_favorite_id == df.team_away, 'away_favorite'] = 1\n",
    "df.home_favorite.fillna(0, inplace=True)\n",
    "df.away_favorite.fillna(0, inplace=True)\n",
    "\n",
    "# creating over / under column (fill na with 0's)\n",
    "df.loc[((df.score_home + df.score_away) > df.over_under_line), 'over'] = 1\n",
    "df.over.fillna(0, inplace=True)\n",
    "\n",
    "# stadium neutral and schedule playoff as boolean\n",
    "df['stadium_neutral'] = df.stadium_neutral.astype(int)\n",
    "df['schedule_playoff'] = df.schedule_playoff.astype(int)\n",
    "\n",
    "# change data type of date columns\n",
    "df['schedule_date'] = pd.to_datetime(df['schedule_date'])\n",
    "games_elo['date'] = pd.to_datetime(games_elo['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e8fa25152d1110ec317571ecac47c6def9068e4"
   },
   "outputs": [],
   "source": [
    "# fixing some schedule_week column errors and converting column to integer data type\n",
    "df.loc[(df.schedule_week == '18'), 'schedule_week'] = '17'\n",
    "df.loc[(df.schedule_week == 'Wildcard') | (df.schedule_week == 'WildCard'), 'schedule_week'] = '18'\n",
    "df.loc[(df.schedule_week == 'Division'), 'schedule_week'] = '19'\n",
    "df.loc[(df.schedule_week == 'Conference'), 'schedule_week'] = '20'\n",
    "df.loc[(df.schedule_week == 'Superbowl') | (df.schedule_week == 'SuperBowl'), 'schedule_week'] = '21'\n",
    "df['schedule_week'] = df.schedule_week.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "47c3b91c4ee20bdb61b1aa488c214d2e9e105d5a"
   },
   "outputs": [],
   "source": [
    "# removing extra columns that aren't necessary for analysis\n",
    "df = df[['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n",
    "       'team_away', 'team_favorite_id', 'spread_favorite',\n",
    "       'over_under_line', 'weather_temperature',\n",
    "       'weather_wind_mph', 'score_home', 'score_away',\n",
    "       'stadium_neutral', 'home_favorite', 'away_favorite',\n",
    "       'over']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b07d5565569fc886b6555c2bd53d0dabe6b4766c"
   },
   "outputs": [],
   "source": [
    "# Cleaning games_elo and df to merge correctly\n",
    "wsh_map = {'WSH' : 'WAS'}\n",
    "games_elo.loc[games_elo.team1 == 'WSH', 'team1'] = 'WAS' \n",
    "games_elo.loc[games_elo.team2 == 'WSH', 'team2'] = 'WAS'\n",
    "\n",
    "# fix dates\n",
    "df.loc[(df.schedule_date == '2016-09-19') & (df.team_home == 'MIN'), 'schedule_date'] = datetime.datetime(2016, 9, 18)\n",
    "df.loc[(df.schedule_date == '2017-01-22') & (df.schedule_week == 21), 'schedule_date'] = datetime.datetime(2017, 2, 5)\n",
    "df.loc[(df.schedule_date == '1990-01-27') & (df.schedule_week == 21), 'schedule_date'] = datetime.datetime(1990, 1, 28)\n",
    "df.loc[(df.schedule_date == '1990-01-13'), 'schedule_date'] = datetime.datetime(1990, 1, 14)\n",
    "games_elo.loc[(games_elo.date == '2016-01-09'), 'date'] = datetime.datetime(2016, 1, 10)\n",
    "games_elo.loc[(games_elo.date == '2016-01-08'), 'date'] = datetime.datetime(2016, 1, 9)\n",
    "games_elo.loc[(games_elo.date == '2016-01-16'), 'date'] = datetime.datetime(2016, 1, 17)\n",
    "games_elo.loc[(games_elo.date == '2016-01-15'), 'date'] = datetime.datetime(2016, 1, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e21a8e47ba5f8bd87b33260bb4373019455e5422"
   },
   "outputs": [],
   "source": [
    "# merge games_elo with df\n",
    "df = df.merge(games_elo, left_on=['schedule_date', 'team_home', 'team_away'], right_on=['date', 'team1', 'team2'], how='left')\n",
    "\n",
    "# merge to fix neutral games where team_home and team_away are switched\n",
    "games_elo2 = games_elo.rename(columns={'team1' : 'team2', 'team2' : 'team1', 'elo1_pre' : 'elo2_pre', 'elo2_pre' : 'elo1_pre'})\n",
    "games_elo2['qbelo_prob1'] = 1 - games_elo2.qbelo_prob1\n",
    "df = df.merge(games_elo2, left_on=['schedule_date', 'team_home', 'team_away'], right_on=['date', 'team1', 'team2'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1d8c6ebcbf14eeed0e102d61bcbe48efd1b55f81"
   },
   "outputs": [],
   "source": [
    "# separating merged columns into x and y cols\n",
    "x_cols = ['date_x', 'season_x', 'neutral_x', 'playoff_x', 'team1_x', 'team2_x', 'elo1_pre_x', 'elo2_pre_x',\n",
    "          'qbelo_prob1_x', 'score1_x', 'score2_x']\n",
    "y_cols = ['date_y', 'season_y', 'neutral_y', 'playoff_y', 'team1_y', 'team2_y', 'elo1_pre_y', 'elo2_pre_y',\n",
    "          'qbelo_prob1_y', 'score1_y', 'score2_y']\n",
    "\n",
    "# filling null values for games_elo merged cols\n",
    "for x, y in zip(x_cols, y_cols):\n",
    "    df[x] = df[x].fillna(df[y]) \n",
    "\n",
    "# removing y_cols from dataframe    \n",
    "df = df[['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n",
    "       'team_away', 'team_favorite_id', 'spread_favorite', 'over_under_line',\n",
    "       'weather_temperature', 'weather_wind_mph', 'score_home', 'score_away',\n",
    "       'stadium_neutral', 'home_favorite', 'away_favorite', 'over', 'neutral_x', 'playoff_x',\n",
    "         'elo1_pre_x', 'elo2_pre_x', 'qbelo_prob1_x']]\n",
    "\n",
    "# remove _x ending from column names\n",
    "df.columns = df.columns.str.replace('_x', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "508add6af52293d8b2ae350a019667410c2d99bc"
   },
   "outputs": [],
   "source": [
    "# creating result column df.loc[(df.score_home > df.score_away), 'result'\n",
    "df['result'] = (df.score_home > df.score_away).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b034e3f9f092c1f5cb1c8d3a73e343aff1fdd95d"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c26560c6173d33e68a98a7162f579df86a875077"
   },
   "outputs": [],
   "source": [
    "# all column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ace2fd143f784ebf55cc4fbdadf72e67b002de8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# snapshot of data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6092a801ad7040b186f23d61d2d2158837e9130"
   },
   "outputs": [],
   "source": [
    "# null values by column\n",
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0edf107a0ad338e14c05a806cc9f6daf282c80fe"
   },
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f3563bca7f3e60bbfe48a80f02fa1799e89e5b5b"
   },
   "outputs": [],
   "source": [
    "# some percentages to take into consideration when betting\n",
    "home_win = \"{:.2f}\".format((sum((df.result == 1) & (df.stadium_neutral == 0)) / len(df)) * 100)\n",
    "away_win = \"{:.2f}\".format((sum((df.result == 0) & (df.stadium_neutral == 0)) / len(df)) * 100)\n",
    "under_line = \"{:.2f}\".format((sum((df.score_home + df.score_away) < df.over_under_line) / len(df)) * 100)\n",
    "over_line = \"{:.2f}\".format((sum((df.score_home + df.score_away) > df.over_under_line) / len(df)) * 100)\n",
    "\n",
    "favored = \"{:.2f}\".format((sum(((df.home_favorite == 1) & (df.result == 1)) | ((df.away_favorite == 1) & (df.result == 0)))\n",
    "                           / len(df)) * 100)\n",
    "\n",
    "cover = \"{:.2f}\".format((sum(((df.home_favorite == 1) & ((df.score_away - df.score_home) < df.spread_favorite)) | \n",
    "                             ((df.away_favorite == 1) & ((df.score_home - df.score_away) < df.spread_favorite))) \n",
    "                         / len(df)) * 100)\n",
    "\n",
    "ats = \"{:.2f}\".format((sum(((df.home_favorite == 1) & ((df.score_away - df.score_home) > df.spread_favorite)) | \n",
    "                           ((df.away_favorite == 1) & ((df.score_home - df.score_away) > df.spread_favorite))) \n",
    "                       / len(df)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50b69b7ac23f882179b41efca0d16187e57b25a9"
   },
   "outputs": [],
   "source": [
    "# print all percentages\n",
    "print(\"Number of Games: \" + str(len(df)))\n",
    "print(\"Home Straight Up Win Percentage: \" + home_win + \"%\")\n",
    "print(\"Away Straight Up Win Percentage: \" + away_win + \"%\")\n",
    "print(\"Under Percentage: \" + under_line + \"%\")\n",
    "print(\"Over Percentage: \" + over_line + \"%\")\n",
    "print(\"Favored Win Percentage: \" + favored + \"%\")\n",
    "print(\"Cover The Spread Percentage: \" + cover + \"%\")\n",
    "print(\"Against The Spread Percentage: \" + ats + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "37bc191b8ec52d51047146ed517016061537e8e6"
   },
   "source": [
    "# Creating More Features\n",
    "Features that will help predict whether the home team will win (straight up win in the current version the line doesn't matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03762efad32909a17878dd4641f6fc7a8538445b"
   },
   "outputs": [],
   "source": [
    "# creating 2 separate dataframes with the home teams / scores and the away teams / scores\n",
    "score = df.groupby(['schedule_season', 'schedule_week', 'team_home']).mean()[['score_home', 'score_away']].reset_index()\n",
    "aw_score = df.groupby(['schedule_season', 'schedule_week', 'team_away']).mean()[['score_home', 'score_away']].reset_index()\n",
    "\n",
    "# create total pts column\n",
    "score['point_diff'] = score.score_home - score.score_away\n",
    "aw_score['point_diff'] = aw_score.score_away - aw_score.score_home\n",
    "\n",
    "# append the two dataframes\n",
    "score = score.append(aw_score, ignore_index=True, sort=True)\n",
    "\n",
    "# fill null values\n",
    "score.team_home.fillna(score.team_away, inplace=True)\n",
    "\n",
    "# sort by season and week \n",
    "score.sort_values(['schedule_season', 'schedule_week'], ascending = [True, True], inplace=True)\n",
    "\n",
    "# removing unneeded columns & changing column name \n",
    "score = score[['schedule_season', 'schedule_week', 'team_home', 'point_diff']]\n",
    "score.rename(columns={'team_home' : 'team'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "62c0572d8c3edce58b8e5706827c1a6442d93893"
   },
   "outputs": [],
   "source": [
    "# dictionary of dataframes - separate dataframe for each team\n",
    "tm_dict = {}\n",
    "for key in score.team.unique():\n",
    "    tm_dict[key] = score[score.team == key].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eabe3580f357a22ee35fd23221fa28fbbb58383a"
   },
   "outputs": [],
   "source": [
    "# dataframe to populate\n",
    "pts_diff = pd.DataFrame()\n",
    "\n",
    "# for loop to create a rolling average of the previous games for each season\n",
    "for yr in score.schedule_season.unique():\n",
    "    for tm in score.team.unique():\n",
    "        data = tm_dict[tm].copy()\n",
    "        data = data[data.schedule_season == yr]\n",
    "        \n",
    "        data.loc[:, 'avg_pts_diff'] = data.point_diff.shift().expanding().mean()\n",
    "        \n",
    "        pts_diff = pts_diff.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af6509add71d0aed48291229e9a6bc51b7faa2b3"
   },
   "outputs": [],
   "source": [
    "# merging to df and changing column names\n",
    "df = df.merge(pts_diff[['schedule_season', 'schedule_week', 'team', 'avg_pts_diff']], \n",
    "              left_on=['schedule_season', 'schedule_week', 'team_home'], right_on=['schedule_season', 'schedule_week', 'team'],\n",
    "              how='left')\n",
    "\n",
    "df.rename(columns={'avg_pts_diff' : 'hm_avg_pts_diff'}, inplace=True)\n",
    "\n",
    "df = df.merge(pts_diff[['schedule_season', 'schedule_week', 'team', 'avg_pts_diff']], \n",
    "              left_on=['schedule_season', 'schedule_week', 'team_away'], right_on=['schedule_season', 'schedule_week', 'team'],\n",
    "              how='left')\n",
    "\n",
    "df.rename(columns={'avg_pts_diff' : 'aw_avg_pts_diff'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4de99a5033fae0882cee066735206097cfcf63c2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# average point differential over entire season\n",
    "total_season = pts_diff.groupby(['schedule_season', 'team']).mean()['point_diff'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9d7ef7dfaecaf0d72aa669427175d0f5345be854"
   },
   "outputs": [],
   "source": [
    "# adding schedule week for merge and adding one to the season for predictions\n",
    "total_season['schedule_week'] = 1\n",
    "total_season['schedule_season'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# differentials for start of the year\n",
    "# total_season.to_csv(\"pointdiff2019.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "420db7e418dc45de6f7d6b5c54d4694877b18c3c"
   },
   "outputs": [],
   "source": [
    "# cleaning of columns\n",
    "df = df[['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n",
    "       'team_away', 'team_favorite_id', 'spread_favorite', 'over_under_line',\n",
    "       'weather_temperature', 'weather_wind_mph', 'score_home', 'score_away', 'stadium_neutral', 'home_favorite',\n",
    "       'away_favorite', 'hm_avg_pts_diff','aw_avg_pts_diff', 'elo1_pre', 'elo2_pre', 'qbelo_prob1', 'over', 'result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "219d0af199bdb1cec2c28c4c5cc67162bd35067f"
   },
   "outputs": [],
   "source": [
    "# merge to have previous seasons average point differential\n",
    "df = df.merge(total_season[['schedule_season', 'schedule_week', 'team', 'point_diff']], \n",
    "              left_on=['schedule_season', 'schedule_week', 'team_home'], right_on=['schedule_season', 'schedule_week', 'team'],\n",
    "              how='left')\n",
    "\n",
    "df.rename(columns={'point_diff' : 'hm_avg_diff'}, inplace=True)\n",
    "\n",
    "df = df.merge(total_season[['schedule_season', 'schedule_week', 'team', 'point_diff']], \n",
    "              left_on=['schedule_season', 'schedule_week', 'team_away'], right_on=['schedule_season', 'schedule_week', 'team'],\n",
    "              how='left')\n",
    "\n",
    "df.rename(columns={'point_diff' : 'aw_avg_diff'}, inplace=True)\n",
    "\n",
    "# fill null values\n",
    "df.hm_avg_pts_diff.fillna(df.hm_avg_diff, inplace=True)\n",
    "df.aw_avg_pts_diff.fillna(df.aw_avg_diff, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e50323851dcd46e24c63235805ebbe1cc54913fc"
   },
   "outputs": [],
   "source": [
    "# cleaning of columns\n",
    "df = df[['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n",
    "       'team_away', 'team_favorite_id', 'spread_favorite', 'over_under_line',\n",
    "       'weather_temperature', 'weather_wind_mph', 'score_home', 'score_away', 'stadium_neutral', 'home_favorite',\n",
    "       'away_favorite', 'hm_avg_pts_diff','aw_avg_pts_diff', 'elo1_pre', 'elo2_pre', 'qbelo_prob1', 'over', 'result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "69e84cc294dc1b4755f21adfae630415968e61ec"
   },
   "outputs": [],
   "source": [
    "# removing all rows with null values\n",
    "df = df.dropna(how='any',axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "71d867b34e089b8217a00c512689d8471020bce5"
   },
   "source": [
    "# Feature and Model Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4f1845a8a9f856d01753346f754d875baff64c8"
   },
   "outputs": [],
   "source": [
    "# initial features possible for model\n",
    "X = df[['schedule_season', 'schedule_week', 'over_under_line', 'spread_favorite', 'weather_temperature', 'weather_wind_mph',\n",
    "        'home_favorite', 'hm_avg_pts_diff','aw_avg_pts_diff', 'elo1_pre', 'elo2_pre', 'qbelo_prob1']]\n",
    "\n",
    "y = df['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a540e487420e29108ffce1c6b53e54bd635cac2"
   },
   "outputs": [],
   "source": [
    "# base model\n",
    "base = LDA()\n",
    "\n",
    "# choose 5 best features\n",
    "rfe = RFE(base, 5)\n",
    "rfe = rfe.fit(X, y)\n",
    "\n",
    "# features\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "782399f6ab72e7beaafba6468234e59973e94f55"
   },
   "outputs": [],
   "source": [
    "# best 5 features chosen by the RFE base model\n",
    "final_x = df[['spread_favorite', 'home_favorite', 'hm_avg_pts_diff', 'elo2_pre', 'qbelo_prob1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d7fbd4a8a83a19d4ea2c5ddd634adefd5f5d442",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare models\n",
    "models = []\n",
    "\n",
    "models.append(('LRG', LogisticRegression(solver='liblinear')))\n",
    "models.append(('KNB', KNeighborsClassifier()))\n",
    "models.append(('GNB', GaussianNB()))\n",
    "models.append(('XGB', xgb.XGBClassifier(random_state=0)))\n",
    "models.append(('RFC', RandomForestClassifier(random_state=0, n_estimators=100)))\n",
    "models.append(('DTC', DecisionTreeClassifier(random_state=0, criterion='entropy', max_depth=5)))\n",
    "\n",
    "# evaluate each model by average and standard deviations of roc auc \n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, m in models:\n",
    "    kfold = model_selection.KFold(n_splits=5, random_state=0)\n",
    "    cv_results = model_selection.cross_val_score(m, final_x, y, cv=kfold, scoring = 'roc_auc')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b2442e79b78251f7c1eb686db17cb6bb8921004"
   },
   "outputs": [],
   "source": [
    "# training and testing data (2017 and 2018)\n",
    "train = df.copy()\n",
    "test = df.copy()\n",
    "train = train.loc[train['schedule_season'] < 2017]\n",
    "test = test.loc[test['schedule_season'] > 2016]\n",
    "X_train = train[['over_under_line', 'spread_favorite', 'home_favorite', 'hm_avg_pts_diff', 'qbelo_prob1']]\n",
    "y_train = train['result']\n",
    "X_test = test[['over_under_line', 'spread_favorite', 'home_favorite', 'hm_avg_pts_diff', 'qbelo_prob1']]\n",
    "y_test = test['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16460de3a3ee54780544133f5fe6492576eb2668",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calibrate probabilities and fit model to training data\n",
    "boost = xgb.XGBClassifier()\n",
    "dtc = DecisionTreeClassifier(max_depth=5, criterion='entropy')\n",
    "lrg = LogisticRegression(solver='liblinear')\n",
    "vote = VotingClassifier(estimators=[('boost', boost), ('dtc', dtc), ('lrg', lrg)], voting='soft')\n",
    "\n",
    "model = CCV(vote, method='isotonic', cv=3)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "623db26a4c942e612f3077ce212d5a524e224245"
   },
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "predicted = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77978d9e72741a355b3350f9606eb72f487fc5f0"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "34d96e10e1f74ce8e1b06b97c7f5f78d7156906f"
   },
   "outputs": [],
   "source": [
    "# ROC AUC Score higher is better while Brier Score the lower the better\n",
    "print(\"Metrics\" + \"\\t\\t\" + \"My Model\" + \"\\t\" + \"Elo Results\")\n",
    "print(\"ROC AUC Score: \" +  \"\\t\" + \"{:.4f}\".format(roc_auc_score(y_test, predicted)) + \"\\t\\t\" + \"{:.4f}\".format(roc_auc_score(test.result, test.qbelo_prob1)))\n",
    "print(\"Brier Score: \" + \"\\t\" + \"{:.4f}\".format(brier_score_loss(y_test, predicted)) + \"\\t\\t\" + \"{:.4f}\".format(brier_score_loss(test.result, test.qbelo_prob1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5170a8bf94c082a41a0922541cc6d7eace41a953"
   },
   "outputs": [],
   "source": [
    "# creating a column with the models probabilities to analyze vs elo fivethirtyeight\n",
    "test.loc[:,'hm_prob'] = predicted\n",
    "test = test[['schedule_season', 'schedule_week', 'team_home', 'team_away', 'qbelo_prob1', 'hm_prob', 'result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "616037841955a33003a6e6be2971312fab17d29d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calulate bets won (only make a bet when probability is greater than / equal to 60% or less than / equal to 40%)\n",
    "test['my_bet_won'] = (((test.hm_prob >= 0.60) & (test.result == 1)) | ((test.hm_prob <= 0.40) & (test.result == 0))).astype(int)\n",
    "test['elo_bet_won'] = (((test.qbelo_prob1 >= 0.60) & (test.result == 1)) | ((test.qbelo_prob1 <= 0.40) & (test.result == 0))).astype(int)\n",
    "\n",
    "# calulate bets lost (only make a bet when probability is greater than / equal to 60% or less than / equal to 40%)\n",
    "test['my_bet_lost'] = (((test.hm_prob >= 0.60) & (test.result == 0)) | ((test.hm_prob <= 0.40) & (test.result == 1))).astype(int)\n",
    "test['elo_bet_lost'] = (((test.qbelo_prob1 >= 0.60) & (test.result == 0)) | ((test.qbelo_prob1 <= 0.40) & (test.result == 1))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "655e04633fffb114efcb7f811f8dc35dcf2cfede"
   },
   "outputs": [],
   "source": [
    "# printing some quick overall results for my model\n",
    "print(\"My Model Win Percentage: \" + \"{:.4f}\".format(test.my_bet_won.sum() / (test.my_bet_lost.sum() + test.my_bet_won.sum())))\n",
    "print(\"Total Number of Bets Won: \" + str(test.my_bet_won.sum()))\n",
    "print(\"Total Number of Bets Made: \" + str((test.my_bet_lost.sum() + test.my_bet_won.sum())))\n",
    "print(\"Possible Games: \" + str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e6d193f84b239e0dea9a055563a556a10020f6f"
   },
   "outputs": [],
   "source": [
    "# printing some quick overall results for fivethirtyeight's ELO model\n",
    "print(\"ELO Model Win Percentage: \" + \"{:.4f}\".format(test.elo_bet_won.sum()/(test.elo_bet_lost.sum() + test.elo_bet_won.sum())))\n",
    "print(\"Total Number of Bets Won: \" + str(test.elo_bet_won.sum()))\n",
    "print(\"Total Number of Bets Made: \" + str((test.elo_bet_lost.sum() + test.elo_bet_won.sum())))\n",
    "print(\"Possible Games: \" + str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9436319d7939345f9de4a1a47476d43efcd4c83f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating week by week results\n",
    "results_df = test.groupby(['schedule_season', 'schedule_week']).agg({'team_home' : 'count', 'my_bet_won' : 'sum', \n",
    "'elo_bet_won' : 'sum', 'my_bet_lost' : 'sum', 'elo_bet_lost' : 'sum'}).reset_index().rename(columns=\n",
    "                                                                                            {'team_home' : 'total_games'})\n",
    "\n",
    "# counting total bets for my model and the ELO model (prob >= 60% or prob <= 40%)\n",
    "results_df['total_bets'] = results_df.my_bet_won + results_df.my_bet_lost\n",
    "results_df['elo_total_bets'] = results_df.elo_bet_won + results_df.elo_bet_lost\n",
    "\n",
    "# creating accuracy columns based on bets made not on total games\n",
    "results_df['bet_accuracy'] = round((results_df.my_bet_won / results_df.total_bets) * 100, 2)\n",
    "results_df['elo_bet_accuracy'] = round((results_df.elo_bet_won / results_df.elo_total_bets) * 100, 2)\n",
    "results_df = results_df[['schedule_season', 'schedule_week', 'bet_accuracy', 'elo_bet_accuracy',\n",
    "                         'total_bets', 'elo_total_bets', 'total_games']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "369b27df233445e376eeb6c74a8f885f8f4b848b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"NFLMoneyLine_model1.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
